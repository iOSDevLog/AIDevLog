{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/iOSDevLog/AIDevLogCode/blob/master/style.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "fmy8mcCLV3ej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8f3a7cc-54b7-49d6-9646-853ad5def08d"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3WfIB38vtiO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "8f16f2d1-cec7-4bc1-c908-7145d52e46d1"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow matplotlib scipy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (0.19.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (39.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.31.1)\n",
            "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.10.0)\n",
            "Requirement already satisfied: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow) (2.6.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XN03rksytuki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "8cb87a6b-9047-4553-ed43-76f88bbb7273"
      },
      "cell_type": "code",
      "source": [
        "# 授权绑定代码\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmp9gr6fgiq/pubring.gpg' created\n",
            "gpg: /tmp/tmp9gr6fgiq/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_a8gzg7Qtufb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "97f178a7-c52a-456f-8d46-9a505d39dbf5"
      },
      "cell_type": "code",
      "source": [
        "# 指定Google Drive云端硬盘的根目录，名为drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1S0_nOI7tuQA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 指定当前的工作文件夹\n",
        "import os\n",
        "\n",
        "# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n",
        "os.chdir(\"drive/Colab Notebooks/style\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RDL_esMt3fp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "a5675e7a-1c45-49db-8b9d-76a1d2ec093e"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.jpg\t\t\t      main_tf.py\t\t\tstyle3.jpg\n",
            "content.jpg\t\t      neural_style_transfer_keras\tstyle4.jpg\n",
            "imagenet-vgg-verydeep-19.mat  neural_style_transfer_tensorflow\tstyle5.jpg\n",
            "imgs\t\t\t      style1.jpg\t\t\tstyle.ipynb\n",
            "main_keras.py\t\t      style2.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H3k5sTmco1uE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "cc441ea8-5120-4abf-a98f-c44cecf9ae21"
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import os\n",
        "import time\n",
        "\n",
        "def the_current_time():\n",
        "\tprint(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(int(time.time()))))\n",
        "\n",
        "#CONTENT_IMG = 'content.jpg'\n",
        "CONTENT_IMG = '5.jpg'\n",
        "STYLE_IMG = 'style5.jpg'\n",
        "OUTPUT_DIR = 'neural_style_transfer_tensorflow/'\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "\tos.mkdir(OUTPUT_DIR)\n",
        "\n",
        "IMAGE_W = 800\n",
        "IMAGE_H = 600\n",
        "COLOR_C = 3\n",
        "\n",
        "NOISE_RATIO = 0.7\n",
        "BETA = 5\n",
        "ALPHA = 100\n",
        "VGG_MODEL = 'imagenet-vgg-verydeep-19.mat'\n",
        "MEAN_VALUES = np.array([123.68, 116.779, 103.939]).reshape((1, 1, 1, 3))\n",
        "\n",
        "def load_vgg_model(path):\n",
        "\t'''\n",
        "\tDetails of the VGG19 model:\n",
        "\t- 0 is conv1_1 (3, 3, 3, 64)\n",
        "\t- 1 is relu\n",
        "\t- 2 is conv1_2 (3, 3, 64, 64)\n",
        "\t- 3 is relu\n",
        "\t- 4 is maxpool\n",
        "\t- 5 is conv2_1 (3, 3, 64, 128)\n",
        "\t- 6 is relu\n",
        "\t- 7 is conv2_2 (3, 3, 128, 128)\n",
        "\t- 8 is relu\n",
        "\t- 9 is maxpool\n",
        "\t- 10 is conv3_1 (3, 3, 128, 256)\n",
        "\t- 11 is relu\n",
        "\t- 12 is conv3_2 (3, 3, 256, 256)\n",
        "\t- 13 is relu\n",
        "\t- 14 is conv3_3 (3, 3, 256, 256)\n",
        "\t- 15 is relu\n",
        "\t- 16 is conv3_4 (3, 3, 256, 256)\n",
        "\t- 17 is relu\n",
        "\t- 18 is maxpool\n",
        "\t- 19 is conv4_1 (3, 3, 256, 512)\n",
        "\t- 20 is relu\n",
        "\t- 21 is conv4_2 (3, 3, 512, 512)\n",
        "\t- 22 is relu\n",
        "\t- 23 is conv4_3 (3, 3, 512, 512)\n",
        "\t- 24 is relu\n",
        "\t- 25 is conv4_4 (3, 3, 512, 512)\n",
        "\t- 26 is relu\n",
        "\t- 27 is maxpool\n",
        "\t- 28 is conv5_1 (3, 3, 512, 512)\n",
        "\t- 29 is relu\n",
        "\t- 30 is conv5_2 (3, 3, 512, 512)\n",
        "\t- 31 is relu\n",
        "\t- 32 is conv5_3 (3, 3, 512, 512)\n",
        "\t- 33 is relu\n",
        "\t- 34 is conv5_4 (3, 3, 512, 512)\n",
        "\t- 35 is relu\n",
        "\t- 36 is maxpool\n",
        "\t- 37 is fullyconnected (7, 7, 512, 4096)\n",
        "\t- 38 is relu\n",
        "\t- 39 is fullyconnected (1, 1, 4096, 4096)\n",
        "\t- 40 is relu\n",
        "\t- 41 is fullyconnected (1, 1, 4096, 1000)\n",
        "\t- 42 is softmax\n",
        "\t'''\n",
        "\tvgg = scipy.io.loadmat(path)\n",
        "\tvgg_layers = vgg['layers']\n",
        "\n",
        "\tdef _weights(layer, expected_layer_name):\n",
        "\t\tW = vgg_layers[0][layer][0][0][2][0][0]\n",
        "\t\tb = vgg_layers[0][layer][0][0][2][0][1]\n",
        "\t\tlayer_name = vgg_layers[0][layer][0][0][0][0]\n",
        "\t\tassert layer_name == expected_layer_name\n",
        "\t\treturn W, b\n",
        "\n",
        "\tdef _conv2d_relu(prev_layer, layer, layer_name):\n",
        "\t\tW, b = _weights(layer, layer_name)\n",
        "\t\tW = tf.constant(W)\n",
        "\t\tb = tf.constant(np.reshape(b, (b.size)))\n",
        "\t\treturn tf.nn.relu(tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b)\n",
        "\n",
        "\tdef _avgpool(prev_layer):\n",
        "\t\treturn tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "\tgraph = {}\n",
        "\tgraph['input']    = tf.Variable(np.zeros((1, IMAGE_H, IMAGE_W, COLOR_C)), dtype='float32')\n",
        "\tgraph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
        "\tgraph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
        "\tgraph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
        "\tgraph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
        "\tgraph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
        "\tgraph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
        "\tgraph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
        "\tgraph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
        "\tgraph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
        "\tgraph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
        "\tgraph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
        "\tgraph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
        "\tgraph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
        "\tgraph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
        "\tgraph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
        "\tgraph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
        "\tgraph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
        "\tgraph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
        "\tgraph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
        "\tgraph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
        "\tgraph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
        "\treturn graph\n",
        "\n",
        "def content_loss_func(sess, model):\n",
        "\tdef _content_loss(p, x):\n",
        "\t\tN = p.shape[3]\n",
        "\t\tM = p.shape[1] * p.shape[2]\n",
        "\t\treturn (1 / (4 * N * M)) * tf.reduce_sum(tf.pow(x - p, 2))\n",
        "\treturn _content_loss(sess.run(model['conv4_2']), model['conv4_2'])\n",
        "\n",
        "STYLE_LAYERS = [('conv1_1', 0.5), ('conv2_1', 1.0), ('conv3_1', 1.5), ('conv4_1', 3.0), ('conv5_1', 4.0)]\n",
        "\n",
        "def style_loss_func(sess, model):\n",
        "\tdef _gram_matrix(F, N, M):\n",
        "\t\tFt = tf.reshape(F, (M, N))\n",
        "\t\treturn tf.matmul(tf.transpose(Ft), Ft)\n",
        "\n",
        "\tdef _style_loss(a, x):\n",
        "\t\tN = a.shape[3]\n",
        "\t\tM = a.shape[1] * a.shape[2]\n",
        "\t\tA = _gram_matrix(a, N, M)\n",
        "\t\tG = _gram_matrix(x, N, M)\n",
        "\t\treturn (1 / (4 * N ** 2 * M ** 2)) * tf.reduce_sum(tf.pow(G - A, 2))\n",
        "\n",
        "\treturn sum([_style_loss(sess.run(model[layer_name]), model[layer_name]) * w for layer_name, w in STYLE_LAYERS])\n",
        "\n",
        "def generate_noise_image(content_image, noise_ratio=NOISE_RATIO):\n",
        "\tnoise_image = np.random.uniform(-20, 20, (1, IMAGE_H, IMAGE_W, COLOR_C)).astype('float32')\n",
        "\tinput_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
        "\treturn input_image\n",
        "\n",
        "def load_image(path):\n",
        "\timage = scipy.misc.imread(path)\n",
        "\timage = scipy.misc.imresize(image, (IMAGE_H, IMAGE_W))\n",
        "\timage = np.reshape(image, ((1, ) + image.shape))\n",
        "\timage = image - MEAN_VALUES\n",
        "\treturn image\n",
        "\n",
        "def save_image(path, image):\n",
        "\timage = image + MEAN_VALUES\n",
        "\timage = image[0]\n",
        "\timage = np.clip(image, 0, 255).astype('uint8')\n",
        "\tscipy.misc.imsave(path, image)\n",
        "\n",
        "the_current_time()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\tcontent_image = load_image(CONTENT_IMG)\n",
        "\tstyle_image = load_image(STYLE_IMG)\n",
        "\tmodel = load_vgg_model(VGG_MODEL)\n",
        "\n",
        "\tinput_image = generate_noise_image(content_image)\n",
        "\tsess.run(tf.global_variables_initializer())\n",
        "\n",
        "\tsess.run(model['input'].assign(content_image))\n",
        "\tcontent_loss = content_loss_func(sess, model)\n",
        "\n",
        "\tsess.run(model['input'].assign(style_image))\n",
        "\tstyle_loss = style_loss_func(sess, model)\n",
        "\n",
        "\ttotal_loss = BETA * content_loss + ALPHA * style_loss\n",
        "\toptimizer = tf.train.AdamOptimizer(2.0)\n",
        "\ttrain = optimizer.minimize(total_loss)\n",
        "\n",
        "\tsess.run(tf.global_variables_initializer())\n",
        "\tsess.run(model['input'].assign(input_image))\n",
        "\n",
        "\tITERATIONS = 2000\n",
        "\tfor i in range(ITERATIONS):\n",
        "\t\tsess.run(train)\n",
        "\t\tif i % 100 == 0:\n",
        "\t\t\toutput_image = sess.run(model['input'])\n",
        "\t\t\tthe_current_time()\n",
        "\t\t\tprint('Iteration %d' % i)\n",
        "\t\t\tprint('Cost: ', sess.run(total_loss))\n",
        "\n",
        "\t\t\tsave_image(os.path.join(OUTPUT_DIR, 'output_%d.jpg' % i), output_image)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-09-11 17:55:53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if issubdtype(ts, int):\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  elif issubdtype(type(size), float):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-09-11 17:56:25\n",
            "Iteration 0\n",
            "Cost:  184519560000.0\n",
            "2018-09-11 17:57:31\n",
            "Iteration 100\n",
            "Cost:  2013287400.0\n",
            "2018-09-11 17:58:30\n",
            "Iteration 200\n",
            "Cost:  858448450.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}